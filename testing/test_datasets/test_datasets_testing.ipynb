{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bb1e7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from util.create_architecture import make_dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e4b8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the data in\n",
    "data_path = \"data/\"\n",
    "\n",
    "def load_single_mean(lookback_game):\n",
    "    X = np.load(data_path + f\"single_mean_lg{lookback_game}_X.npy\")\n",
    "    Y = np.load(data_path + f\"single_mean_lg{lookback_game}_Y.npy\")\n",
    "    ids = np.load(data_path + f\"single_mean_lg{lookback_game}_ids.npy\")\n",
    "    return X, Y, ids\n",
    "\n",
    "def load_single_diff(lookback_game):\n",
    "    X = np.load(data_path + f\"single_diff_lg{lookback_game}_X.npy\")\n",
    "    Y = np.load(data_path + f\"single_diff_lg{lookback_game}_Y.npy\")\n",
    "    ids = np.load(data_path + f\"single_diff_lg{lookback_game}_ids.npy\")\n",
    "    return X, Y, ids\n",
    "\n",
    "def load_double_mean(lookback_game):\n",
    "    X = np.load(data_path + f\"double_mean_lg{lookback_game}_X.npy\")\n",
    "    Y = np.load(data_path + f\"double_mean_lg{lookback_game}_Y.npy\")\n",
    "    ids = np.load(data_path + f\"double_mean_lg{lookback_game}_ids.npy\")\n",
    "    return X, Y, ids\n",
    "\n",
    "def load_double_diff(lookback_game):\n",
    "    X = np.load(data_path + f\"single_diff_lg{lookback_game}_X.npy\")\n",
    "    Y = np.load(data_path + f\"single_diff_lg{lookback_game}_Y.npy\")\n",
    "    ids = np.load(data_path + f\"single_diff_lg{lookback_game}_ids.npy\")\n",
    "    return X, Y, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e29faaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for creating and training the model\n",
    "def eval_models(X, Y, ids, n_models, is_single, model_name):\n",
    "    \n",
    "#     learning_rate = 2e-4\n",
    "#     epochs = 200 # Should always stop early.\n",
    "    \n",
    "    train_pct, test_pct, val_pct = 0.6, 0.2, 0.2\n",
    "    \n",
    "    # Split the data\n",
    "    X_train = X[:int(train_pct*X.shape[0])]\n",
    "    X_test = X[int(train_pct*X.shape[0]):int((train_pct+test_pct)*X.shape[0])]\n",
    "    X_val = X[-int(val_pct*X.shape[0]):]\n",
    "    \n",
    "    Y_train = Y[:int(train_pct*X.shape[0])]\n",
    "    Y_test = Y[int(train_pct*X.shape[0]):int((train_pct+test_pct)*X.shape[0])]\n",
    "    Y_val = Y[-int(val_pct*X.shape[0]):]\n",
    "    \n",
    "    ids_train = ids[:int(train_pct*X.shape[0])]\n",
    "    ids_test = ids[int(train_pct*X.shape[0]):int((train_pct+test_pct)*X.shape[0])]\n",
    "    ids_val = ids[-int(val_pct*X.shape[0]):]\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    # Loop through and train models\n",
    "    trained_models = []\n",
    "    for _ in range(n_models):\n",
    "        \n",
    "        # Define the model structure\n",
    "        model = make_dense_model(input_size=X.shape[1], hidden_layer_sizes=[10], \n",
    "                                 regularization=None, activation=\"relu\")\n",
    "        \n",
    "        # Compile the model\n",
    "        loss = tf.keras.losses.BinaryCrossentropy()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        metrics = ['accuracy']\n",
    "        model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        \n",
    "        # Fit the model\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1)]\n",
    "        model.fit(x=X_train, y=Y_train, validation_data=(X_val, Y_val), \n",
    "                  batch_size=64, epochs=epochs, callbacks=callbacks, verbose=0)\n",
    "        \n",
    "        trained_models.append(model)\n",
    "        \n",
    "        # Print out a quick evaluation\n",
    "        val_acc = model.evaluate(X_val, Y_val, return_dict=True, verbose=0)['accuracy']\n",
    "        print(f\"Validation Accuracy: {val_acc*100:.2f}%\")\n",
    "        \n",
    "    # Evaluate all the models together\n",
    "    if is_single:\n",
    "        final_accuracy = evaluate_single_models(trained_models, X_val, Y_val, ids_val)\n",
    "    else:\n",
    "        final_accuracy = evaluate_double_models(trained_models, X_val, Y_val)\n",
    "        \n",
    "    print(f\"{model_name} Final Accuracy: {final_accuracy*100:.2f}%.\")\n",
    "    return final_accuracy\n",
    "        \n",
    "\n",
    "    \n",
    "def evaluate_single_models(models, X, Y, ids):\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = np.array([m.predict(X, verbose=0).reshape(-1) for m in models])\n",
    "    predictions = predictions.mean(axis=0) > 0.500\n",
    "    \n",
    "    # Use ids to find the same games\n",
    "    right, wrong = 0, 0\n",
    "    for game_id in np.unique(ids):\n",
    "        game_mask = ids == game_id\n",
    "        \n",
    "        if np.sum(game_mask) != 2:\n",
    "            continue\n",
    "        \n",
    "        game_preds = predictions[game_mask]\n",
    "        game_Y = Y[game_mask]\n",
    "        \n",
    "        if game_Y[np.argmax(game_preds)]:\n",
    "            right += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "            \n",
    "    accuracy = right / (right + wrong)\n",
    "    return accuracy\n",
    "    \n",
    "def evaluate_double_models(models, X, Y):\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = np.array([m.predict(X, verbose=0).reshape(-1) for m in models])\n",
    "    predictions = predictions.mean(axis=0) > 0.500\n",
    "    \n",
    "    accuracy = np.mean(predictions == Y)\n",
    "    return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c70761b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: early stopping\n",
      "Validation Accuracy: 52.99%\n",
      "Single Mean Final Accuracy: 50.97%.\n",
      "Epoch 76: early stopping\n",
      "Validation Accuracy: 52.79%\n",
      "Single Diff Final Accuracy: 51.89%.\n",
      "Epoch 63: early stopping\n",
      "Validation Accuracy: 53.39%\n",
      "Double Mean Final Accuracy: 53.39%.\n",
      "Epoch 45: early stopping\n",
      "Validation Accuracy: 52.96%\n",
      "Double Diff Final Accuracy: 52.96%.\n"
     ]
    }
   ],
   "source": [
    "# Define the testing parameters\n",
    "lookback_games = [1]\n",
    "n_models = 1\n",
    "\n",
    "learning_rate = 2e-4\n",
    "epochs = 200 # Should always stop early.\n",
    "\n",
    "# Loop through the data and store the accuracies\n",
    "all_accuracies = np.zeros((len(lookback_games), 4+1))\n",
    "for i, lookback_game in enumerate(lookback_games):\n",
    "    \n",
    "    # Single Mean Data\n",
    "    X, Y, ids = load_single_mean(lookback_game)\n",
    "    single_mean_accuracy = eval_models(X, Y, ids, n_models, is_single=True, model_name=\"Single Mean\")\n",
    "    \n",
    "    # Single Diff Data\n",
    "    X, Y, ids = load_single_diff(lookback_game)\n",
    "    single_diff_accuracy = eval_models(X, Y, ids, n_models, is_single=True, model_name=\"Single Diff\")\n",
    "    \n",
    "    # Double Mean Data\n",
    "    X, Y, ids = load_double_mean(lookback_game)\n",
    "    double_mean_accuracy = eval_models(X, Y, ids, n_models, is_single=False, model_name=\"Double Mean\")\n",
    "    \n",
    "    # Double Diff Data\n",
    "    X, Y, ids = load_double_diff(lookback_game)\n",
    "    double_diff_accuracy = eval_models(X, Y, ids, n_models, is_single=False, model_name=\"Double Diff\")\n",
    "    \n",
    "    # Track them (first column stores the lookback game value)\n",
    "    all_accuracies[i] = [lookback_game, single_mean_accuracy, single_diff_accuracy, double_mean_accuracy, \n",
    "                         double_diff_accuracy]\n",
    "    \n",
    "# Save the tracking array\n",
    "np.save(\"results/data_type_results.npy\", all_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4d18325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ff9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
